{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRU_with_the_LuongAttention.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ALkidbf3cfL"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import os\n",
        "import io\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "path1 = '/content/drive/MyDrive/sourcelang.txt'\n",
        "path2='/content/drive/MyDrive/targetlang.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2w098sC3p6p"
      },
      "source": [
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "            if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess(s):\n",
        "    s = unicode_to_ascii(s.lower().strip())\n",
        "    s = re.sub(r\"([?.!,¿])\", r\" \\1 \", s)\n",
        "    s = re.sub(r'[\" \"]+', \" \", s)\n",
        "    s = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", s)\n",
        "    s = s.strip()\n",
        "    # adding start-of-sequence (sos) token and end-of-sequence (eos) token\n",
        "    s = '<sos> ' + s + ' <eos>'\n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wrmoBhF3p9l",
        "outputId": "561d1649-b145-4c98-9ca9-e69622f79ce7"
      },
      "source": [
        "def tokenize(language):\n",
        "    # Use <unk> token for unkown words\n",
        "    tokenizer = Tokenizer(filters='', oov_token='<unk>')\n",
        "    tokenizer.fit_on_texts(language)\n",
        "\n",
        "    tensor = tokenizer.texts_to_sequences(language)\n",
        "    tensor = pad_sequences(tensor, padding='post')\n",
        "    return tensor, tokenizer\n",
        "\n",
        "def load_dataset(path1,path2 ,num_examples=None, prints=False) :\n",
        "    lines = open(path1, encoding='UTF-8').read().strip().split('\\n')\n",
        "    lines2 = open(path2, encoding='UTF-8').read().strip().split('\\n')\n",
        "    \n",
        "    # list containing word pairs in the format: [[ENGLISH], [FRENCH]]\n",
        "    word_pairs = [preprocess(l) for l in lines[:num_examples]]\n",
        "    input_lang=word_pairs\n",
        "    word_pairs2 = [preprocess(l) for l in lines2[:num_examples]]\n",
        "    targ_lang=word_pairs2\n",
        "\n",
        "    if prints:\n",
        "        print(targ_lang[-1])\n",
        "        print(input_lang[-1])\n",
        "        return\n",
        "    \n",
        "    input_tensor, input_tokenizer = tokenize(input_lang)\n",
        "    targ_tensor, targ_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "    return input_tensor, targ_tensor, input_tokenizer, targ_tokenizer\n",
        "\n",
        "load_dataset(path1,path2,num_examples=60000, prints=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sos> i think was azam understand not . <eos>\n",
            "<sos> i think azam did not understand . <eos>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Kai6vzR3qAG",
        "outputId": "c4b6de17-36d4-4b24-989a-af9b60fd9e44"
      },
      "source": [
        "inp_tensor, targ_tensor, inp_lang, targ_lang = load_dataset(path1,path2)\n",
        "inp_tensor_train, inp_tensor_val, \\\n",
        "targ_tensor_train, targ_tensor_val = \\\n",
        "train_test_split(inp_tensor, targ_tensor, test_size=0.2)\n",
        "print(\"Input tensors: \", inp_tensor_train.shape, inp_tensor_val.shape)\n",
        "print(\"Target tensors: \", targ_tensor_train.shape, targ_tensor_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tensors:  (68176, 15) (17044, 15)\n",
            "Target tensors:  (68176, 17) (17044, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqrzAcc33qC0",
        "outputId": "6243542f-62b4-4c41-8f6e-2057af8cc13f"
      },
      "source": [
        "buffer_size = len(inp_tensor_train)\n",
        "batch_size = 16\n",
        "steps_per_epoch = len(inp_tensor_train) // batch_size\n",
        "embedding_dim = 300\n",
        "units = 1024 \n",
        "vocab_inp_size = len(inp_lang.index_word) + 1\n",
        "vocab_targ_size = len(targ_lang.index_word) + 1\n",
        "\n",
        "def create_dataset(shuffle=True, buffer_size=buffer_size, batch_size=batch_size):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((inp_tensor_train, targ_tensor_train))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size)\n",
        "    ds = ds.batch(batch_size, drop_remainder=True)\n",
        "    return ds.prefetch(1)\n",
        "\n",
        "train_dataset = create_dataset()\n",
        "valid_dataset = create_dataset(shuffle=False)\n",
        "inp_batch, targ_batch = next(iter(train_dataset))\n",
        "inp_batch.shape, targ_batch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([16, 15]), TensorShape([16, 17]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NN8U7mS3qFt",
        "outputId": "e45f3465-f166-4128-d62f-b7aac4b8d213"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, LSTM, dot, Dense,GRU\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, encoder_units, batch_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_size= batch_size\n",
        "        self.encoder_units=encoder_units\n",
        "        self.embedding=tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru= tf.keras.layers.GRU(encoder_units, \n",
        "                                      return_sequences=True,\n",
        "                                      return_state=True,\n",
        "                                      recurrent_initializer='glorot_uniform'\n",
        "                                     )\n",
        "    \n",
        "    def call(self, x, hidden):\n",
        "        #pass the input x to the embedding layer\n",
        "        x= self.embedding(x)\n",
        "        # pass the embedding and the hidden state to GRU\n",
        "        output, state = self.gru(x, initial_state=hidden)\n",
        "        return output, state\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_size, self.encoder_units))\n",
        "\n",
        "\n",
        "encoder = Encoder(vocab_inp_size,embedding_dim,units,batch_size)\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden= encoder(inp_batch,sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (16, 15, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (16, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eTRZLd_RY5l"
      },
      "source": [
        "def print_shapes(enc_output, dec_state, score, attention_weights, context_vector):\n",
        "    print(f\"btach_size: {batch_size}\")\n",
        "    print(f\"seq_length: {inp_tensor_train.shape[1]}\")\n",
        "    print(f\"enc_units: {units}\")\n",
        "    print()\n",
        "    print(f\"enc_output:        {enc_output.shape}\")\n",
        "    print(f\"dec_state:         {dec_state.shape}\")\n",
        "    print(f\"score:             {score.shape}\")\n",
        "    print(f\"attention_weights: {attention_weights.shape}\")\n",
        "    print(f\"context_vector:    {context_vector.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkNEgQWcXXvB"
      },
      "source": [
        "def LuongAttention(query, values):\n",
        "  \n",
        "  query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "  score = tf.matmul(query_with_time_axis, values, transpose_b=True)\n",
        "\n",
        "  attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "  attention_weights = tf.reshape(attention_weights, shape=(-1, attention_weights.shape[2], 1))\n",
        "\n",
        "\n",
        "  context_vector = attention_weights * values\n",
        "  context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "  return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vi_A3NwSXo4P",
        "outputId": "9e136c44-dddf-48df-9cc8-df97b1e1654e"
      },
      "source": [
        "\n",
        "attention_result, attention_weights = LuongAttention(sample_hidden, sample_output)\n",
        "\n",
        "print(\"context vector shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context vector shape: (batch size, units) (16, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (16, 15, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "razpFMkVXx_p"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_size):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "\n",
        "    context_vector, attention_weights = LuongAttention(hidden, enc_output)\n",
        "\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WF8Ka6VPYT55",
        "outputId": "03f0760f-99ce-4329-b402-202531acd554"
      },
      "source": [
        "decoder = Decoder(vocab_targ_size, embedding_dim, units, batch_size)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((batch_size, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (16, 8095)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgNymnl9RZBZ"
      },
      "source": [
        "def print_status_bar(iteration, total, loss):    \n",
        "    metrics = \"loss: {:.4f}\".format(loss) \n",
        "    end = \"\" if iteration < total else \"\\n\"\n",
        "    print(\"\\r{}/{} - \".format(iteration, total) + metrics,end=end)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iV6eTZb_RZDb"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "  return tf.reduce_mean(loss_)\n",
        "\n",
        "@tf.function\n",
        "def train_step(inp_batch, targ_batch, enc_state_h):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_state_h= encoder(inp_batch, enc_state_h)\n",
        "        # at the beginning we set the decoder state to the encoder state\n",
        "        dec_state_h = enc_state_h\n",
        "\n",
        "        # at the begining we feed the <sos> token as input for the decoder, \n",
        "        # then we will feed the target as input\n",
        "        dec_input = tf.expand_dims([targ_lang.word_index['<sos>']] * batch_size, 1)\n",
        "        for t in range(1, targ_batch.shape[1]): # targ_batch.shape[1] == seq length\n",
        "            predictions, dec_state_h, _ = decoder(dec_input, dec_state_h, enc_output)\n",
        "            loss += loss_function(targ_batch[:, t], predictions)\n",
        "            dec_input = tf.expand_dims(targ_batch[:, t], 1)\n",
        "\n",
        "    batch_loss = loss / int(targ_batch.shape[1])\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    return batch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FAGibq8RZFz"
      },
      "source": [
        "epochs = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(\"Epoch {}/{}\".format(epoch + 1, epochs))\n",
        "    enc_state_h= encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "    \n",
        "    for (batch, (inp, targ)) in enumerate(train_dataset.take(steps_per_epoch)):\n",
        "        batch_loss = train_step(inp, targ, enc_state_h)\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        print_status_bar(batch, steps_per_epoch, batch_loss.numpy())\n",
        "    print_status_bar(steps_per_epoch, steps_per_epoch, total_loss / steps_per_epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gq0SPoe33qJM"
      },
      "source": [
        "def evaluate(sentence, targ_tensor, inp_tensor):\n",
        "    # targ_tensor.shape[1] == max seq length for the target language (EN)\n",
        "    # inp_tensor.shape[1] == max seq length for the input language (FR)\n",
        "    attention_plot = np.zeros((targ_tensor.shape[1], inp_tensor.shape[1]))\n",
        "    \n",
        "    sentence = preprocess(sentence)\n",
        "\n",
        "    inputs = inp_lang.texts_to_sequences([sentence])\n",
        "    inputs = pad_sequences(inputs, maxlen=inp_tensor.shape[1], padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    result = ''\n",
        "\n",
        "    enc_state_h =tf.zeros((1, units))\n",
        "    enc_output, enc_state_h= encoder(inputs, enc_state_h)\n",
        "    dec_state_h = enc_state_h\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<sos>']], 0)\n",
        "\n",
        "    for t in range(targ_tensor.shape[1]):\n",
        "        predictions, dec_state_h, attention_weights = decoder(dec_input,dec_state_h,enc_output)\n",
        "        \n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        # attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "        result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "        # stop prediction\n",
        "        if targ_lang.index_word[predicted_id] == '<eos>':\n",
        "            return result, sentence\n",
        "\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "    return result, sentence\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBJgpztyYZ1q"
      },
      "source": [
        "# function for plotting the attention weights to visualize how the model works internally\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "    \n",
        "  ax.set_xticklabels([''] + sentence, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def translate(sentence, ground_truth=None, plot_weights=False):\n",
        "    result, sentence = evaluate(sentence, targ_tensor, inp_tensor)\n",
        "\n",
        "    print(f'{\"Input:\":15s} {sentence}')\n",
        "    print(f'{\"Prediction:\":15s} {result}')\n",
        "    if ground_truth: print(f'{\"Ground truth:\":15s} {ground_truth}') \n",
        "    \n",
        "    if plot_weights:\n",
        "        attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "        plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ522zrRYZ5g"
      },
      "source": [
        "def preprocess_sequence(seq, language):\n",
        "    sentence = language.sequences_to_texts([seq.numpy()])[0]\n",
        "    sentence = sentence.split(' ')\n",
        "    sentence = [s for s in sentence if s != '<sos>' and s != '<eos>' and s != '<unk>']\n",
        "    return ' '.join(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qolU44uYZ7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f11fa1f-65f0-4397-eccd-515f2b2f7113"
      },
      "source": [
        "for inp_batch, targ_batch in train_dataset.take(100):\n",
        "    for inp, targ in zip(inp_batch, targ_batch):\n",
        "        sentence = preprocess_sequence(inp, inp_lang)\n",
        "        ground_truth = preprocess_sequence(targ, targ_lang)\n",
        "        translate(sentence, ground_truth)\n",
        "        print()\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:          <sos> i write poems in my free time . <eos>\n",
            "Prediction:     i my free write . <eos> \n",
            "Ground truth:   i my free time poems write .\n",
            "\n",
            "Input:          <sos> khurum was not wearing cowboy boots . <eos>\n",
            "Prediction:     was khurum boots wear now not . <eos> \n",
            "Ground truth:   was khurum cowboy boots wear now not .\n",
            "\n",
            "Input:          <sos> the crow is eating grass . <eos>\n",
            "Prediction:     crow grass eat now . <eos> \n",
            "Ground truth:   crow grass eat now .\n",
            "\n",
            "Input:          <sos> i think we will be fine . <eos>\n",
            "Prediction:     i think we fine be after . <eos> \n",
            "Ground truth:   i think we fine be after .\n",
            "\n",
            "Input:          <sos> he is chubby . <eos>\n",
            "Prediction:     he chubby . <eos> \n",
            "Ground truth:   he chubby .\n",
            "\n",
            "Input:          <sos> he was dressed in blue . <eos>\n",
            "Prediction:     was he blue dress . <eos> \n",
            "Ground truth:   was he blue dress .\n",
            "\n",
            "Input:          <sos> fasten your seat belt please . <eos>\n",
            "Prediction:     fasten . <eos> \n",
            "Ground truth:   fasten your seat belt please .\n",
            "\n",
            "Input:          <sos> durani said i was going to die . <eos>\n",
            "Prediction:     was durani say was durani say was durani say was durani say was durani say was durani \n",
            "Ground truth:   was durani say was i die go .\n",
            "\n",
            "Input:          <sos> adnan and i were best friends . <eos>\n",
            "Prediction:     was adnan i best friends . <eos> \n",
            "Ground truth:   was adnan i best friends .\n",
            "\n",
            "Input:          <sos> i like wine . <eos>\n",
            "Prediction:     i wine like . <eos> \n",
            "Ground truth:   i wine like .\n",
            "\n",
            "Input:          <sos> do not park your car here . <eos>\n",
            "Prediction:     here my car here my car here my car here my car here my car here my \n",
            "Ground truth:   here your car park not .\n",
            "\n",
            "Input:          <sos> azan made dinner plans with humna . <eos>\n",
            "Prediction:     was azan humna dinner make . <eos> \n",
            "Ground truth:   was azan humna dinner plans make .\n",
            "\n",
            "Input:          <sos> father will have been going to office . <eos>\n",
            "Prediction:     father office go to full after now . <eos> \n",
            "Ground truth:   father office go to full after now .\n",
            "\n",
            "Input:          <sos> wahid is a very nice boy . <eos>\n",
            "Prediction:     wahid very nice boy . <eos> \n",
            "Ground truth:   wahid very nice boy .\n",
            "\n",
            "Input:          <sos> was gardener wearing turban . <eos>\n",
            "Prediction:     was gardner turban wear now yes no ? <eos> \n",
            "Ground truth:   was gardener turban wear now yes no ?\n",
            "\n",
            "Input:          <sos> muzammil is in church . <eos>\n",
            "Prediction:     muzammil in church . <eos> \n",
            "Ground truth:   muzammil in church .\n",
            "\n",
            "Input:          <sos> hayat was wearing his new hat . <eos>\n",
            "Prediction:     was hayat his new shirt wear now . <eos> \n",
            "Ground truth:   was hayat his new hat wear now .\n",
            "\n",
            "Input:          <sos> nobody realized hasnayn was in pain . <eos>\n",
            "Prediction:     was hasnayn realize was hasnayn realize was hasnayn realize was hasnayn realize was hasnayn realize was hasnayn \n",
            "Ground truth:   was nobody realize was hasnayn pain .\n",
            "\n",
            "Input:          <sos> touch it . <eos>\n",
            "Prediction:     it memorize . <eos> \n",
            "Ground truth:   it touch .\n",
            "\n",
            "Input:          <sos> i know that fazal is talented . <eos>\n",
            "Prediction:     i know that fazal talented . <eos> \n",
            "Ground truth:   i know that fazal talented .\n",
            "\n",
            "Input:          <sos> i had to fix the toaster . <eos>\n",
            "Prediction:     was i toaster fix had . <eos> \n",
            "Ground truth:   was i toaster fix had .\n",
            "\n",
            "Input:          <sos> has he not returned the money . <eos>\n",
            "Prediction:     he money return full not yes no ? <eos> \n",
            "Ground truth:   he money return full not yes no ?\n",
            "\n",
            "Input:          <sos> she is a friend of my wife . <eos>\n",
            "Prediction:     my wife friend . <eos> \n",
            "Ground truth:   she my wife friend .\n",
            "\n",
            "Input:          <sos> he has made the baseball team . <eos>\n",
            "Prediction:     he baseball team make full . <eos> \n",
            "Ground truth:   he baseball team make full .\n",
            "\n",
            "Input:          <sos> i found these . <eos>\n",
            "Prediction:     was i find . <eos> \n",
            "Ground truth:   was i find .\n",
            "\n",
            "Input:          <sos> ayesha had been washing her hands . <eos>\n",
            "Prediction:     was ayesha her hands wash full now . <eos> \n",
            "Ground truth:   was ayesha her hands wash full now .\n",
            "\n",
            "Input:          <sos> master was not controlling the ox . <eos>\n",
            "Prediction:     was master ox control now not . <eos> \n",
            "Ground truth:   was master ox control now not .\n",
            "\n",
            "Input:          <sos> he went by the post office . <eos>\n",
            "Prediction:     was he post office go . <eos> \n",
            "Ground truth:   was he post office go .\n",
            "\n",
            "Input:          <sos> i just got your email . <eos>\n",
            "Prediction:     was i just email get . <eos> \n",
            "Ground truth:   was i your email get .\n",
            "\n",
            "Input:          <sos> i know that sharjeel is lazy . <eos>\n",
            "Prediction:     i know that sharjeel lazy . <eos> \n",
            "Ground truth:   i know that sharjeel lazy .\n",
            "\n",
            "Input:          <sos> i have heard so much about you . <eos>\n",
            "Prediction:     i you so hear full . <eos> \n",
            "Ground truth:   i you much so hear full .\n",
            "\n",
            "Input:          <sos> she lived a long life . <eos>\n",
            "Prediction:     was she long life live . <eos> \n",
            "Ground truth:   was she long life live .\n",
            "\n",
            "Input:          <sos> jalaal is not rude . <eos>\n",
            "Prediction:     jalaal rude not . <eos> \n",
            "Ground truth:   jalaal rude not .\n",
            "\n",
            "Input:          <sos> uqbah seemed like a very nice man . <eos>\n",
            "Prediction:     was uqbah very nice man seem . <eos> \n",
            "Ground truth:   was uqbah very nice man seem .\n",
            "\n",
            "Input:          <sos> jamayel and i sat down to talk . <eos>\n",
            "Prediction:     was jamayel i sit down . <eos> \n",
            "Ground truth:   was jamayel i sit down .\n",
            "\n",
            "Input:          <sos> umais told me halima was unemployed . <eos>\n",
            "Prediction:     was umais halima unemployed . <eos> \n",
            "Ground truth:   was umais me tell was halima unemployed .\n",
            "\n",
            "Input:          <sos> sameer said that he was suspicious . <eos>\n",
            "Prediction:     was he suspicious . <eos> \n",
            "Ground truth:   was sameer say that was he suspicious .\n",
            "\n",
            "Input:          <sos> javed asked bushra to marry him . <eos>\n",
            "Prediction:     was javed bushra him marry ask . <eos> \n",
            "Ground truth:   was javed bushra him marry ask .\n",
            "\n",
            "Input:          <sos> sharoz has a good firm handshake . <eos>\n",
            "Prediction:     sharoz firm handshake handshake handshake handshake handshake handshake handshake handshake handshake handshake handshake handshake handshake handshake handshake \n",
            "Ground truth:   sharoz good firm handshake has .\n",
            "\n",
            "Input:          <sos> i am going to be happy . <eos>\n",
            "Prediction:     i happy be go now . <eos> \n",
            "Ground truth:   i happy be go now .\n",
            "\n",
            "Input:          <sos> i stayed at home all day monday . <eos>\n",
            "Prediction:     was i home afternoon come . <eos> \n",
            "Ground truth:   was i home all day stay .\n",
            "\n",
            "Input:          <sos> asghar fell into a deep sleep . <eos>\n",
            "Prediction:     was asghar deep sleep . <eos> \n",
            "Ground truth:   was asghar deep sleep fall .\n",
            "\n",
            "Input:          <sos> khalil was not listening to humna . <eos>\n",
            "Prediction:     was khalil humna listen now not . <eos> \n",
            "Ground truth:   was khalil humna listen now not .\n",
            "\n",
            "Input:          <sos> monun was coming down the hill . <eos>\n",
            "Prediction:     was monun hill come down now . <eos> \n",
            "Ground truth:   was monun hill come down now .\n",
            "\n",
            "Input:          <sos> hadi enjoyed rida s story . <eos>\n",
            "Prediction:     was hadi enjoy rida enjoy rida enjoy rida enjoy rida enjoy rida enjoy rida enjoy rida enjoy \n",
            "Ground truth:   was hadi enjoy rida story .\n",
            "\n",
            "Input:          <sos> i tried to get aslam to drive . <eos>\n",
            "Prediction:     was i aslam aslam aslam aslam aslam aslam aslam aslam aslam aslam aslam aslam aslam aslam aslam \n",
            "Ground truth:   was i aslam drive get try .\n",
            "\n",
            "Input:          <sos> faseeh asked me to find khola . <eos>\n",
            "Prediction:     was faseeh me khola find ask . <eos> \n",
            "Ground truth:   was faseeh me khola find ask .\n",
            "\n",
            "Input:          <sos> i buried it . <eos>\n",
            "Prediction:     was i it bury . <eos> \n",
            "Ground truth:   was i it bury .\n",
            "\n",
            "Input:          <sos> sharjeel was remarkably shy . <eos>\n",
            "Prediction:     was sharjeel remarkably remarkably remarkably remarkably remarkably remarkably remarkably remarkably remarkably remarkably remarkably remarkably remarkably remarkably remarkably \n",
            "Ground truth:   was sharjeel remarkably shy .\n",
            "\n",
            "Input:          <sos> i doubt nawab will cry . <eos>\n",
            "Prediction:     i doubt nawab cry after . <eos> \n",
            "Ground truth:   i doubt nawab cry after .\n",
            "\n",
            "Input:          <sos> are they friends ? <eos>\n",
            "Prediction:     they friends yes no ? <eos> \n",
            "Ground truth:   they friends yes no ?\n",
            "\n",
            "Input:          <sos> i need water . <eos>\n",
            "Prediction:     i water need . <eos> \n",
            "Ground truth:   i water need .\n",
            "\n",
            "Input:          <sos> has not been filled in the blanks . <eos>\n",
            "Prediction:     blanks fill full now not . <eos> \n",
            "Ground truth:   blanks fill full now not yes no ?\n",
            "\n",
            "Input:          <sos> i think i am going crazy . <eos>\n",
            "Prediction:     i think i think i think i think i think i think i think i think i \n",
            "Ground truth:   i think i crazy go now .\n",
            "\n",
            "Input:          <sos> i feel slightly sick . <eos>\n",
            "Prediction:     i suddenly clearly sick feel . <eos> \n",
            "Ground truth:   i slightly sick feel .\n",
            "\n",
            "Input:          <sos> ahmad made an omelet . <eos>\n",
            "Prediction:     was ahmad omelet make . <eos> \n",
            "Ground truth:   was ahmad omelet make .\n",
            "\n",
            "Input:          <sos> i know that ranvir loves basketball . <eos>\n",
            "Prediction:     i know that ranvir basketball love . <eos> \n",
            "Ground truth:   i know that ranvir basketball love .\n",
            "\n",
            "Input:          <sos> he lost his balance and fell down . <eos>\n",
            "Prediction:     was he fall down fall down fall down fall down fall down fall down fall down fall \n",
            "Ground truth:   was he his balance lose fall down .\n",
            "\n",
            "Input:          <sos> had a robber not come to him . <eos>\n",
            "Prediction:     was a robber him come to full not yes no ? <eos> \n",
            "Ground truth:   was a robber him come to full not yes no ?\n",
            "\n",
            "Input:          <sos> moon is careful . <eos>\n",
            "Prediction:     moon careful . <eos> \n",
            "Ground truth:   moon careful .\n",
            "\n",
            "Input:          <sos> we prayed together . <eos>\n",
            "Prediction:     was we together pray . <eos> \n",
            "Ground truth:   was we together pray .\n",
            "\n",
            "Input:          <sos> i know i have been very stupid . <eos>\n",
            "Prediction:     i know i know i know i know i know i know i know i know i \n",
            "Ground truth:   i know i very stupid full .\n",
            "\n",
            "Input:          <sos> the bus driver opened the door . <eos>\n",
            "Prediction:     was bus open . <eos> \n",
            "Ground truth:   was bus driver door open .\n",
            "\n",
            "Input:          <sos> you are wasting precious time . <eos>\n",
            "Prediction:     you precious time waste now . <eos> \n",
            "Ground truth:   you precious time waste now .\n",
            "\n",
            "Input:          <sos> i can not go until he comes . <eos>\n",
            "Prediction:     i go not until go not until go not until go not until go not until go \n",
            "Ground truth:   i go not until he come .\n",
            "\n",
            "Input:          <sos> she kissed him on the cheek . <eos>\n",
            "Prediction:     was she class him kiss him kiss him kiss him kiss him kiss him kiss him kiss \n",
            "Ground truth:   was she cheek him kiss .\n",
            "\n",
            "Input:          <sos> asghar came back three hours later . <eos>\n",
            "Prediction:     was asghar three hours back three hours back three hours back three hours back three hours back \n",
            "Ground truth:   was asghar three hours back come .\n",
            "\n",
            "Input:          <sos> bilal called ayesha for help . <eos>\n",
            "Prediction:     was bilal help ayesha help ayesha help ayesha help ayesha help ayesha help ayesha help ayesha help \n",
            "Ground truth:   was bilal help ayesha call .\n",
            "\n",
            "Input:          <sos> jamil was not like that . <eos>\n",
            "Prediction:     was jamil like not . <eos> \n",
            "Ground truth:   was jamil like that not .\n",
            "\n",
            "Input:          <sos> i will make you a sandwich . <eos>\n",
            "Prediction:     i you a sandwich make after . <eos> \n",
            "Ground truth:   i you a sandwich make after .\n",
            "\n",
            "Input:          <sos> hamza seemed gullible . <eos>\n",
            "Prediction:     was hamza gullible seem . <eos> \n",
            "Ground truth:   was hamza gullible seem .\n",
            "\n",
            "Input:          <sos> rahul got an a . <eos>\n",
            "Prediction:     was rahul a get . <eos> \n",
            "Ground truth:   was rahul a . get .\n",
            "\n",
            "Input:          <sos> i want shahzad killed . <eos>\n",
            "Prediction:     i want . <eos> \n",
            "Ground truth:   i want was shahzad kill .\n",
            "\n",
            "Input:          <sos> the sky grew darker and darker . <eos>\n",
            "Prediction:     was sky darker darker darker darker darker darker darker darker darker darker darker darker darker darker darker \n",
            "Ground truth:   was sky darker darker grow .\n",
            "\n",
            "Input:          <sos> i was not looking at that boy . <eos>\n",
            "Prediction:     was i boy look now not . <eos> \n",
            "Ground truth:   was i boy look not now .\n",
            "\n",
            "Input:          <sos> i had fun talking with zabhi . <eos>\n",
            "Prediction:     was i fun talk had . <eos> \n",
            "Ground truth:   was i fun zabhi talk had .\n",
            "\n",
            "Input:          <sos> i remember seeing him somewhere . <eos>\n",
            "Prediction:     i him somewhere see remember . <eos> \n",
            "Ground truth:   i him somewhere see remember .\n",
            "\n",
            "Input:          <sos> i will have been taking bath daily . <eos>\n",
            "Prediction:     daily i bath take full after now . <eos> \n",
            "Ground truth:   daily i bath take full after now .\n",
            "\n",
            "Input:          <sos> you will have to trust sami . <eos>\n",
            "Prediction:     you sami trust full after . <eos> \n",
            "Ground truth:   you sami trust full after .\n",
            "\n",
            "Input:          <sos> i haven t seen khalil for weeks . <eos>\n",
            "Prediction:     i weeks khalil i weeks khalil i weeks khalil i weeks khalil i weeks khalil i weeks \n",
            "Ground truth:   i weeks khalil see full not .\n",
            "\n",
            "Input:          <sos> had he not been taking photos . <eos>\n",
            "Prediction:     was he photo take full now not yes no ? <eos> \n",
            "Ground truth:   was he photo take full now not yes no ?\n",
            "\n",
            "Input:          <sos> laal was tried for murder . <eos>\n",
            "Prediction:     was laal murder try . <eos> \n",
            "Ground truth:   was laal murder try .\n",
            "\n",
            "Input:          <sos> i have my own tv show . <eos>\n",
            "Prediction:     i tv show have . <eos> \n",
            "Ground truth:   i own tv show have .\n",
            "\n",
            "Input:          <sos> aalim lost control . <eos>\n",
            "Prediction:     was aalim control lose . <eos> \n",
            "Ground truth:   was aalim control lose .\n",
            "\n",
            "Input:          <sos> shoaib seemed clever . <eos>\n",
            "Prediction:     was shoaib clever seem . <eos> \n",
            "Ground truth:   was shoaib clever seem .\n",
            "\n",
            "Input:          <sos> adnan did not even try to win . <eos>\n",
            "Prediction:     was adnan even win try not . <eos> \n",
            "Ground truth:   was adnan even win try not .\n",
            "\n",
            "Input:          <sos> it was not important . <eos>\n",
            "Prediction:     was it important not . <eos> \n",
            "Ground truth:   was it important not .\n",
            "\n",
            "Input:          <sos> i know that shazim is wrong . <eos>\n",
            "Prediction:     i know that shazim wrong . <eos> \n",
            "Ground truth:   i know that shazim wrong .\n",
            "\n",
            "Input:          <sos> i wanted to pay . <eos>\n",
            "Prediction:     was i pay want . <eos> \n",
            "Ground truth:   was i pay want .\n",
            "\n",
            "Input:          <sos> it was six o clock . <eos>\n",
            "Prediction:     was it six o o o o o o o o o o o o o o \n",
            "Ground truth:   was it six o clock .\n",
            "\n",
            "Input:          <sos> irfan said that there was one left . <eos>\n",
            "Prediction:     was there leave . <eos> \n",
            "Ground truth:   was irfan say that there was one left .\n",
            "\n",
            "Input:          <sos> the star was not indicating light . <eos>\n",
            "Prediction:     was star light indicate now not . <eos> \n",
            "Ground truth:   was star light indicate now not .\n",
            "\n",
            "Input:          <sos> maybe it was you . <eos>\n",
            "Prediction:     was maybe it you . <eos> \n",
            "Ground truth:   was maybe it you .\n",
            "\n",
            "Input:          <sos> i had a nice time . <eos>\n",
            "Prediction:     was i nice time had . <eos> \n",
            "Ground truth:   was i nice time had .\n",
            "\n",
            "Input:          <sos> do you believe rahib ? <eos>\n",
            "Prediction:     you rahib believe yes no ? <eos> \n",
            "Ground truth:   you rahib believe yes no ?\n",
            "\n",
            "Input:          <sos> they will have thrown woodcutter s turban . <eos>\n",
            "Prediction:     they woodcutter turban throw full after . <eos> \n",
            "Ground truth:   they woodcutter turban throw full after .\n",
            "\n",
            "Input:          <sos> huzaifa just wants my money . <eos>\n",
            "Prediction:     huzaifa just my money just my money just my money just my money just my money just \n",
            "Ground truth:   huzaifa just my money want .\n",
            "\n",
            "Input:          <sos> i am not dreaming . <eos>\n",
            "Prediction:     i true not . <eos> \n",
            "Ground truth:   i dream now not .\n",
            "\n",
            "Input:          <sos> mujtaba is a biker . <eos>\n",
            "Prediction:     mujtaba biker . <eos> \n",
            "Ground truth:   mujtaba biker .\n",
            "\n",
            "Input:          <sos> mustafa likes basketball . <eos>\n",
            "Prediction:     mustafa basketball like . <eos> \n",
            "Ground truth:   mustafa basketball like .\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efJaF25LqNal"
      },
      "source": [
        "def gettranslation(sentence, ground_truth=None, plot_weights=True):\n",
        "    result, sentence = evaluate(sentence, targ_tensor, inp_tensor)\n",
        "\n",
        "    # print(f'{\"Input:\":15s} {sentence}')\n",
        "    # print(f'{\"Prediction:\":15s} {result}')\n",
        "    # if ground_truth: print(f'{\"Ground truth:\":15s} {ground_truth}') \n",
        "    \n",
        "    if plot_weights:\n",
        "        attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "        plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n",
        "\n",
        "    return sentence,result,ground_truth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc2poyIgKX_S"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P55rObmVKhR_"
      },
      "source": [
        "groundt=list()\n",
        "predict=list()\n",
        "\n",
        "numsamples=100\n",
        "\n",
        "for inp_batch, targ_batch in train_dataset.take(numsamples):\n",
        "    for inp, targ in zip(inp_batch, targ_batch):\n",
        "        sentence = preprocess_sequence(inp, inp_lang)\n",
        "        ground_truth = preprocess_sequence(targ, targ_lang)\n",
        "        s,r,g=gettranslation(sentence, ground_truth, plot_weights=False)\n",
        "        groundt.append(ground_truth)\n",
        "        predict.append(r)\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCGwwMH2Lxzw"
      },
      "source": [
        "j=0\n",
        "for i in groundt:\n",
        "  j=j+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDHIJe4gNYKZ",
        "outputId": "54f807aa-9d21-471f-81c3-a6ff2398a0d1"
      },
      "source": [
        "j"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhYMHvLhNV8n",
        "outputId": "23529424-addf-4c70-b4f9-df458a5558a7"
      },
      "source": [
        "groundt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['she his room go yes no ?',\n",
              " 'was mahi dua close friends .',\n",
              " 'was he many dangers expose .',\n",
              " 'azan uninsure .',\n",
              " 'the dog milkman bark at now after not .',\n",
              " 'was my grandfather house build .',\n",
              " 'i i rahib know believe not .',\n",
              " 'was her mother him advise not .',\n",
              " 'she loses the soil .',\n",
              " 'was said me tell that was he happy .',\n",
              " 'was she beautiful hat show .',\n",
              " 'i zabhi rid get now .',\n",
              " 'was khayam them closely look .',\n",
              " 'i come now .',\n",
              " 'was i think was you quit go .',\n",
              " 'was i help here come .',\n",
              " 'i several moheem times meet full .',\n",
              " 'i her sister very much like .',\n",
              " 'was i it notice .',\n",
              " 'i you advance know let after .',\n",
              " 'was i lot learn hope now .',\n",
              " 'was nazeer gazala do see .',\n",
              " 'i think fahad cooperative be not .',\n",
              " 'was i pakistan work use .',\n",
              " 'was i play want .',\n",
              " 'was izatullah later short time leave .',\n",
              " 'i now know .',\n",
              " 'i them see .',\n",
              " 'i my room clean full now not yes no ?',\n",
              " 'arif room clean yes no ?',\n",
              " 'you able come be after yes no ?',\n",
              " 'was pigeons grass sit on full .',\n",
              " 'i often sameer questions ask .',\n",
              " 'was i wrong it do .',\n",
              " 'was manan our house come want .',\n",
              " 'irfan ul haq curious .',\n",
              " 'was arif overly optimistic not .',\n",
              " 'was i adeel his knuckles crack hear .',\n",
              " 'was sajid alert .',\n",
              " 'was she her left hand burned .',\n",
              " 'was i rest home stay .',\n",
              " 'was i place love use .',\n",
              " 'was i even there not .',\n",
              " 'was manan drown .',\n",
              " 'was i public high school go .',\n",
              " 'was ajab interest not .',\n",
              " 'was i buzdar my suitcase carry get .',\n",
              " 'was i hear najeeb tough .',\n",
              " 'she her mother help full now yes no ?',\n",
              " 'was shamas his cell phone handed .',\n",
              " 'was she my aid come .',\n",
              " 'i my life like .',\n",
              " 'i aslam here tonight be expect .',\n",
              " 'i my reasons have .',\n",
              " 'was arman his day us tell .',\n",
              " 'was hassan stalls go to full now not .',\n",
              " 'i you contradict now not .',\n",
              " 'gardener turban wear full after not .',\n",
              " 'was jan his teacher call .',\n",
              " 'was you book like yes no ?',\n",
              " 'i really wish you me call .',\n",
              " 'he think he it prove .',\n",
              " 'musawir prospector .',\n",
              " 'tulat think was para win .',\n",
              " 'it drink down .',\n",
              " 'was i women like .',\n",
              " 'asma out go not yes no ?',\n",
              " 'was aslam altogether wrong not .',\n",
              " 'was sharjeel me tell was gazala sick .',\n",
              " 'was i note write .',\n",
              " 'we library speak full after now not .',\n",
              " 'i your t shirt dry after .',\n",
              " 'i know not when was aman die .',\n",
              " 'you me faris remember after .',\n",
              " 'was they desert pass through full .',\n",
              " 'it very dangerous system .',\n",
              " 'just it stop .',\n",
              " 'i stairs go down now .',\n",
              " 'was bears cold water sit in full now .',\n",
              " 'i you it do let not .',\n",
              " 'azaan art love .',\n",
              " 'was we anyone tell not .',\n",
              " 'was arif go there again want .',\n",
              " 'i terrible mistake make full .',\n",
              " 'she live there anymore not .',\n",
              " 'was ameer unfriendly be use .',\n",
              " 'buzdar famous artist .',\n",
              " 'you my keys get full .',\n",
              " 'was i today work go not .',\n",
              " 'was i wrong approach choose .',\n",
              " 'little grains of sand the land make full not .',\n",
              " 'i usually outside eat .',\n",
              " 'was safeer it do deny .',\n",
              " 'i it here like not .',\n",
              " 'i it touch yes no ?',\n",
              " 'was they old woman run towards not yes no ?',\n",
              " 'shahzad often late stay out .',\n",
              " 'was safeer say that was he unconcerned .',\n",
              " 'i know it tough be after .',\n",
              " 'was i just confuse .']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnSBy8mlMVJw",
        "outputId": "6e9482fb-d970-418b-f990-dc8aabe96cd3"
      },
      "source": [
        "len(predict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z0tSrwlN5E2"
      },
      "source": [
        "file1 = open(\"/content/predict.txt\",\"w\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "payzPpysO18X"
      },
      "source": [
        "z=0\n",
        "for i in predict:\n",
        "  file1.writelines(i+'\\n')\n",
        "  z=z+1\n",
        "file1.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hdIajyDPh7X",
        "outputId": "a0ef24df-24c6-49e7-f2cc-fbaffa9b951a"
      },
      "source": [
        "z"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp6ZIiNvPrQP"
      },
      "source": [
        "file1 = open(\"/content/predict.txt\",\"r+\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFckLvO2QLgj"
      },
      "source": [
        "file2 = open(\"/content/ground.txt\",\"w\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvMDTClHQUQ8"
      },
      "source": [
        "z=0\n",
        "for i in groundt:\n",
        "  file2.writelines(i+'\\n')\n",
        "  z=z+1\n",
        "file2.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "glahKQW7PyPA",
        "outputId": "ae7ebb2a-c223-44ae-ef02-6cc964bc39a7"
      },
      "source": [
        "file1.read()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'she his room go yes no ? <eos> \\nwas mahi dua close friends . <eos> \\nwas he many dangers absorb . <eos> \\nazan uninsure . <eos> \\nthe dog milkman bark at now after not . <eos> \\nwas my grandfather house house house house house house house house house house house house house house \\ni know not i know not i know not i know not i know not i know \\nwas her mother him advise not . <eos> \\nthey robbers abdul qadir jilani the soil the soil the soil the soil the soil the soil \\nwas he happy . <eos> \\nwas she beautiful hat show . <eos> \\ni zabhi rid get now . <eos> \\nwas khayam them closely look . <eos> \\ni come now . <eos> \\nwas you go . <eos> \\nwas i help . <eos> \\ni several moheem moheem moheem moheem moheem moheem moheem moheem moheem moheem moheem moheem moheem moheem moheem \\ni her sister a much like . <eos> \\nwas i it notice . <eos> \\ni you know after . <eos> \\nwas i lot learn hope now . <eos> \\nwas nazeer gazala do see . <eos> \\ni think fahad cooperative be not . <eos> \\nwas i pakistan work use . <eos> \\nwas i play want . <eos> \\nwas izatullah later short time leave . <eos> \\ni now know . <eos> \\ni them see . <eos> \\ni my room clean full now not yes no ? <eos> \\narif room clean yes no ? <eos> \\nyou able come be after yes no ? <eos> \\nwas pigeons grass sit on full . <eos> \\ni sameer questions ask . <eos> \\nwas i it wrong . <eos> \\nwas manan our house come want . <eos> \\nirfan ul haq curious . <eos> \\nwas arif optimistic not . <eos> \\nwas adeel crack hear adeel crack hear adeel crack hear adeel crack hear adeel crack hear adeel \\nwas sajid alert . <eos> \\nwas she her left burned . <eos> \\nwas i home stay . <eos> \\nwas i this place use . <eos> \\nwas i even there not . <eos> \\nwas manan drown . <eos> \\nwas i high school go . <eos> \\nwas ajab interest not . <eos> \\nwas i my suitcase carry get . <eos> \\nwas i hear najeeb get najeeb get najeeb get najeeb get najeeb get najeeb get najeeb get \\nshe her mother help full now yes no ? <eos> \\nwas shamas phone handed . <eos> \\nwas she my aid come . <eos> \\ni my life like . <eos> \\ni aslam here tonight be expect . <eos> \\ni my reasons have . <eos> \\nwas arman his day us tell . <eos> \\nwas hassan stalls go to full now not . <eos> \\ni you contradict now not . <eos> \\ngardener turban wear full after not . <eos> \\nwas jan his teacher call . <eos> \\nwas you book like yes no ? <eos> \\ni really you me call . <eos> \\nhe it prove . <eos> \\nmusawir prospector . <eos> \\ntulat think was para always think was para always think was para always think was para always \\nit drink down . <eos> \\nwas i women like . <eos> \\nasma out go not yes no ? <eos> \\nwas aslam altogether altogether altogether altogether altogether altogether altogether altogether altogether altogether altogether altogether altogether altogether altogether \\nwas sharjeel me sick . <eos> \\nwas i note write . <eos> \\nwe library speak full after now not . <eos> \\ni your shirt dry after . <eos> \\ni know not when was aman die . <eos> \\nyou me remember after . <eos> \\nwas they desert pass through full . <eos> \\nit very dangerous . <eos> \\njust it stop . <eos> \\ni stairs go down now . <eos> \\nwas bears cold water sit in full now . <eos> \\ni you it do let not . <eos> \\nazaan art love . <eos> \\nwas we anyone tell not . <eos> \\nwas arif there again want . <eos> \\ni terrible mistake make full . <eos> \\nshe live there anymore not . <eos> \\nwas ameer unfriendly be use . <eos> \\nbuzdar famous artist . <eos> \\nyou my keys get full . <eos> \\nwas i today work go not . <eos> \\nwas i wrong approach choose . <eos> \\nlittle grains of sand the land make full not . <eos> \\ni usually outside eat . <eos> \\nwas safeer it do . <eos> \\ni it here like not . <eos> \\ni it touch yes no ? <eos> \\nwas they old woman run towards not yes no ? <eos> \\nshahzad often late stay out . <eos> \\nwas he unconcerned . <eos> \\ni know it tough be after . <eos> \\nwas i just confuse . <eos> \\n'"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eM5MSEKFNbD9",
        "outputId": "e0ed5c7e-478f-4d77-a316-59e4a8b3ca7f"
      },
      "source": [
        "predict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['she his room go yes no ? <eos> ',\n",
              " 'was mahi dua close friends . <eos> ',\n",
              " 'was he many dangers absorb . <eos> ',\n",
              " 'azan uninsure . <eos> ',\n",
              " 'the dog milkman bark at now after not . <eos> ',\n",
              " 'was my grandfather house house house house house house house house house house house house house house ',\n",
              " 'i know not i know not i know not i know not i know not i know ',\n",
              " 'was her mother him advise not . <eos> ',\n",
              " 'they robbers abdul qadir jilani the soil the soil the soil the soil the soil the soil ',\n",
              " 'was he happy . <eos> ',\n",
              " 'was she beautiful hat show . <eos> ',\n",
              " 'i zabhi rid get now . <eos> ',\n",
              " 'was khayam them closely look . <eos> ',\n",
              " 'i come now . <eos> ',\n",
              " 'was you go . <eos> ',\n",
              " 'was i help . <eos> ',\n",
              " 'i several moheem moheem moheem moheem moheem moheem moheem moheem moheem moheem moheem moheem moheem moheem moheem ',\n",
              " 'i her sister a much like . <eos> ',\n",
              " 'was i it notice . <eos> ',\n",
              " 'i you know after . <eos> ',\n",
              " 'was i lot learn hope now . <eos> ',\n",
              " 'was nazeer gazala do see . <eos> ',\n",
              " 'i think fahad cooperative be not . <eos> ',\n",
              " 'was i pakistan work use . <eos> ',\n",
              " 'was i play want . <eos> ',\n",
              " 'was izatullah later short time leave . <eos> ',\n",
              " 'i now know . <eos> ',\n",
              " 'i them see . <eos> ',\n",
              " 'i my room clean full now not yes no ? <eos> ',\n",
              " 'arif room clean yes no ? <eos> ',\n",
              " 'you able come be after yes no ? <eos> ',\n",
              " 'was pigeons grass sit on full . <eos> ',\n",
              " 'i sameer questions ask . <eos> ',\n",
              " 'was i it wrong . <eos> ',\n",
              " 'was manan our house come want . <eos> ',\n",
              " 'irfan ul haq curious . <eos> ',\n",
              " 'was arif optimistic not . <eos> ',\n",
              " 'was adeel crack hear adeel crack hear adeel crack hear adeel crack hear adeel crack hear adeel ',\n",
              " 'was sajid alert . <eos> ',\n",
              " 'was she her left burned . <eos> ',\n",
              " 'was i home stay . <eos> ',\n",
              " 'was i this place use . <eos> ',\n",
              " 'was i even there not . <eos> ',\n",
              " 'was manan drown . <eos> ',\n",
              " 'was i high school go . <eos> ',\n",
              " 'was ajab interest not . <eos> ',\n",
              " 'was i my suitcase carry get . <eos> ',\n",
              " 'was i hear najeeb get najeeb get najeeb get najeeb get najeeb get najeeb get najeeb get ',\n",
              " 'she her mother help full now yes no ? <eos> ',\n",
              " 'was shamas phone handed . <eos> ',\n",
              " 'was she my aid come . <eos> ',\n",
              " 'i my life like . <eos> ',\n",
              " 'i aslam here tonight be expect . <eos> ',\n",
              " 'i my reasons have . <eos> ',\n",
              " 'was arman his day us tell . <eos> ',\n",
              " 'was hassan stalls go to full now not . <eos> ',\n",
              " 'i you contradict now not . <eos> ',\n",
              " 'gardener turban wear full after not . <eos> ',\n",
              " 'was jan his teacher call . <eos> ',\n",
              " 'was you book like yes no ? <eos> ',\n",
              " 'i really you me call . <eos> ',\n",
              " 'he it prove . <eos> ',\n",
              " 'musawir prospector . <eos> ',\n",
              " 'tulat think was para always think was para always think was para always think was para always ',\n",
              " 'it drink down . <eos> ',\n",
              " 'was i women like . <eos> ',\n",
              " 'asma out go not yes no ? <eos> ',\n",
              " 'was aslam altogether altogether altogether altogether altogether altogether altogether altogether altogether altogether altogether altogether altogether altogether altogether ',\n",
              " 'was sharjeel me sick . <eos> ',\n",
              " 'was i note write . <eos> ',\n",
              " 'we library speak full after now not . <eos> ',\n",
              " 'i your shirt dry after . <eos> ',\n",
              " 'i know not when was aman die . <eos> ',\n",
              " 'you me remember after . <eos> ',\n",
              " 'was they desert pass through full . <eos> ',\n",
              " 'it very dangerous . <eos> ',\n",
              " 'just it stop . <eos> ',\n",
              " 'i stairs go down now . <eos> ',\n",
              " 'was bears cold water sit in full now . <eos> ',\n",
              " 'i you it do let not . <eos> ',\n",
              " 'azaan art love . <eos> ',\n",
              " 'was we anyone tell not . <eos> ',\n",
              " 'was arif there again want . <eos> ',\n",
              " 'i terrible mistake make full . <eos> ',\n",
              " 'she live there anymore not . <eos> ',\n",
              " 'was ameer unfriendly be use . <eos> ',\n",
              " 'buzdar famous artist . <eos> ',\n",
              " 'you my keys get full . <eos> ',\n",
              " 'was i today work go not . <eos> ',\n",
              " 'was i wrong approach choose . <eos> ',\n",
              " 'little grains of sand the land make full not . <eos> ',\n",
              " 'i usually outside eat . <eos> ',\n",
              " 'was safeer it do . <eos> ',\n",
              " 'i it here like not . <eos> ',\n",
              " 'i it touch yes no ? <eos> ',\n",
              " 'was they old woman run towards not yes no ? <eos> ',\n",
              " 'shahzad often late stay out . <eos> ',\n",
              " 'was he unconcerned . <eos> ',\n",
              " 'i know it tough be after . <eos> ',\n",
              " 'was i just confuse . <eos> ']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv73eSk-YZ9o"
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu,SmoothingFunction\n",
        "g1=list()\n",
        "g2=list()\n",
        "g3=list()\n",
        "g4=list()\n",
        "\n",
        "groundt=list()\n",
        "predict=list()\n",
        "cc = SmoothingFunction()\n",
        "def bleu_score(numsamples):\n",
        "  for inp_batch, targ_batch in train_dataset.take(numsamples):\n",
        "    for inp, targ in zip(inp_batch, targ_batch):\n",
        "        sentence = preprocess_sequence(inp, inp_lang)\n",
        "        ground_truth = preprocess_sequence(targ, targ_lang)\n",
        "        s,r,g=gettranslation(sentence, ground_truth, plot_weights=False)\n",
        "        groundt.append(ground_truth)\n",
        "        predict.append(r)\n",
        "        break\n",
        "\n",
        "bleu_score(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoP0a7Pw5kxs",
        "outputId": "e954f808-306a-4c2e-9ef8-bdb3592c68d1"
      },
      "source": [
        "predict[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i yet pay full not . <eos> ',\n",
              " 'it tasty yes no ? <eos> ',\n",
              " 'you us hear yes no ? <eos> ']"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgK_ZwKMYZ_m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8ab825d-6b98-4485-ae4b-dc6981474746"
      },
      "source": [
        "result=list()\n",
        "l=0\n",
        "j=list()\n",
        "# for i in predict:\n",
        "j=[n.replace('<eos>','') for n in predict]\n",
        "print(j[:10])\n",
        "x=[z.rstrip() for z in j]\n",
        "print(x[:10])\n",
        "print(groundt[:10])\n",
        "# # predict[1].split()[:-1]\n",
        "i=0\n",
        "\n",
        "# while i<len(predict):\n",
        "#   predict[i]=predict[i].replace('<eos>', \"\")\n",
        "#   i+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i yet pay full not .  ', 'it tasty yes no ?  ', 'you us hear yes no ?  ', 'let me think .  ', 'was waleed dark walk down .  ', 'i new shoes need .  ', 'was i particularly happy feel not .  ', 'was i look down .  ', 'was i floor sweep .  ', 'i my behavior behavior behavior behavior behavior behavior behavior behavior behavior behavior behavior behavior behavior behavior behavior ']\n",
            "['i yet pay full not .', 'it tasty yes no ?', 'you us hear yes no ?', 'let me think .', 'was waleed dark walk down .', 'i new shoes need .', 'was i particularly happy feel not .', 'was i look down .', 'was i floor sweep .', 'i my behavior behavior behavior behavior behavior behavior behavior behavior behavior behavior behavior behavior behavior behavior behavior']\n",
            "['i yet pay full not .', 'it tasty yes no ?', 'you us hear yes no ?', 'let me think .', 'was waleed dark hallway walk down .', 'i new shoes need .', 'was i particularly happy feel not .', 'was i down look .', 'was i floor sweep .', 'i my recent behavior regret .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDkW7F6cYaCt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "486f66d4-06d6-40d8-d3d5-406bc3fdd249"
      },
      "source": [
        "len(predict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVUVjI0L07Z7",
        "outputId": "602aa56b-bee8-427c-f3a9-075156f69b14"
      },
      "source": [
        "groundt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['was i bus get off .',\n",
              " 'was azan us not here swim tell not .',\n",
              " 'i yet breakfast eat full not .',\n",
              " 'was i iqbal me alone leave ask .',\n",
              " 'i way help out i can .',\n",
              " 'was her mother him advise full now not yes no ?',\n",
              " 'i know why was ismail karachi come .',\n",
              " 'was subhan time track lose .',\n",
              " 'i hope lose start now .',\n",
              " 'was she plane fly yes no ?',\n",
              " 'he very handsome .',\n",
              " 'was madni curious but was dua not .',\n",
              " 'was i chess shoaib beat .',\n",
              " 'it tense situation .',\n",
              " 'blanks fill full after now not yes no ?',\n",
              " 'was amanullah me the job get .',\n",
              " 'arif room clean full .',\n",
              " 'was my feet hurt .',\n",
              " 'i hope i anyone offend full not .',\n",
              " 'was we intrude mean not .',\n",
              " 'was we wrong turn take .',\n",
              " 'ismail try .',\n",
              " 'i i you know think not .',\n",
              " 'bride bright red dress wear .',\n",
              " 'was he wink sleep not .',\n",
              " 'i know that i be after .',\n",
              " 'was laal home his umbrella leave .',\n",
              " 'i know it my fault .',\n",
              " 'he often his parents write .',\n",
              " 'was i see him road cross .',\n",
              " 'doctor my teeth check now after .',\n",
              " 'teacher paintings check full now .',\n",
              " 'i believe that madni me love .',\n",
              " 'was she her way lost now .',\n",
              " 'was i october back surgery had .',\n",
              " 'fazal disorganize .',\n",
              " 'you there go out not .',\n",
              " 'was it whole day hard rain .',\n",
              " 'was i know you stay .',\n",
              " 'we go down now .',\n",
              " 'inam finally marry get now .',\n",
              " 'you know i very stubborn .',\n",
              " 'was aleem his food touch not .',\n",
              " 'was i bet was huzaifa it enjoy .',\n",
              " 'was i just you see come .',\n",
              " 'was i think ajay ready be .',\n",
              " 'was shehryar mistakes lot make .',\n",
              " 'i barely my eyes open keep .',\n",
              " 'was storm tree blow down .',\n",
              " 'was i gold watch give .',\n",
              " 'was mustafa find out when ?',\n",
              " 'he boy find full after not .',\n",
              " 'was it dangerous .',\n",
              " 'was afnan bad cold week had .',\n",
              " 'was i vulnerable feel .',\n",
              " 'you my friend be after yes no ?',\n",
              " 'was i french letter write .',\n",
              " 'truthful boy same answer reply with after not .',\n",
              " 'he you look now .',\n",
              " 'was we just rafi talk .',\n",
              " 'was i think was you canadian .',\n",
              " 'was i karachi stay had .',\n",
              " 'it seem she you hate .',\n",
              " 'was musayyab hospital later die .',\n",
              " 'was nabi trap .',\n",
              " 'jalaal my car use let not .',\n",
              " 'i think your theory incorrect .',\n",
              " 'was jalaal fatima other splashed .',\n",
              " 'was i young innocent .',\n",
              " 'was they their engagement call off .',\n",
              " 'me here stop let .',\n",
              " 'was they some coins put not .',\n",
              " 'mahi very funny .',\n",
              " 'was i queasy bit feel .',\n",
              " 'was i know you wait not .',\n",
              " 'was mudassir see fatima fear eyes .',\n",
              " 'there very little was time leave .',\n",
              " 'was i great vacation had .',\n",
              " 'i not meals eat try not .',\n",
              " 'was they it again do .',\n",
              " 'you it see full yes no ?',\n",
              " 'he river go to full after now not .',\n",
              " 'he approve after not .',\n",
              " 'was it terrorism .',\n",
              " 'i it doubt begin now .',\n",
              " 'you me excuse full after .',\n",
              " 'ishtiyaq help but look not .',\n",
              " 'was i myself a new camera buy .',\n",
              " 'i see after if abrar here .',\n",
              " 'i stay after if you want .',\n",
              " 'was we school french study .',\n",
              " 'was he his house fence build .',\n",
              " 'shahid strange kid .',\n",
              " 'numan writer .',\n",
              " 'inam rain or shine go intends .',\n",
              " 'i someone see now .',\n",
              " 'was i very nervous .',\n",
              " 'i still think we ok be .',\n",
              " 'was numan windows roll down .',\n",
              " 'was aafaq afia talk let not .']"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1L3mimU_yEf7",
        "outputId": "8ee6bbec-6a18-4fd8-e52c-c09b24865463"
      },
      "source": [
        "x "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['was i bus get off .',\n",
              " 'was azan us not .',\n",
              " 'i yet breakfast eat full not .',\n",
              " 'was i iqbal me alone leave ask .',\n",
              " 'i can .',\n",
              " 'was her mother him advise full now not yes no ?',\n",
              " 'i know why was ismail karachi come .',\n",
              " 'was subhan time track lose .',\n",
              " 'i hope lose start start start start start start start start start start start start start start',\n",
              " 'was she plane fly yes no ?',\n",
              " 'he very handsome .',\n",
              " 'was madni curious but was madni curious but was madni curious but was madni curious but was',\n",
              " 'was i chess shoaib beat .',\n",
              " 'it tense situation .',\n",
              " 'blanks fill full after now not yes no ?',\n",
              " 'was amanullah me the job get .',\n",
              " 'arif room clean full .',\n",
              " 'was my feet hurt .',\n",
              " 'i hope i hope i hope i hope i hope i hope i hope i hope i',\n",
              " 'was we intrude mean not .',\n",
              " 'was we wrong turn take .',\n",
              " 'ismail try .',\n",
              " 'i i i i i i i i i i i i i i i i i',\n",
              " 'bride bright red dress wear .',\n",
              " 'was he wink sleep not .',\n",
              " 'i know that i know that i know that i know that i know that i know',\n",
              " 'was laal home his umbrella leave .',\n",
              " 'i know it my fault .',\n",
              " 'he often his parents write .',\n",
              " 'was i see him road cross see him road cross see him road cross see him road',\n",
              " 'doctor my teeth check now after .',\n",
              " 'teacher paintings check full now .',\n",
              " 'i believe that madni me love .',\n",
              " 'was she her way lost now .',\n",
              " 'was i october back surgery had .',\n",
              " 'fazal disorganize .',\n",
              " 'you there go out not .',\n",
              " 'was it whole day hard hard hard hard hard hard hard hard hard hard hard hard hard',\n",
              " 'was i know you stay .',\n",
              " 'we go down now .',\n",
              " 'inam finally marry get now .',\n",
              " 'you know i very stubborn .',\n",
              " 'was aleem his food touch not .',\n",
              " 'was i bet was i bet was i bet was i bet was i bet was i',\n",
              " 'was i just you see come .',\n",
              " 'was i think ajay ready be .',\n",
              " 'was shehryar mistakes lot make .',\n",
              " 'i barely my eyes open keep .',\n",
              " 'was storm blow down .',\n",
              " 'was i gold watch give .',\n",
              " 'was mustafa find out when ?',\n",
              " 'he boy find full after not .',\n",
              " 'was it dangerous .',\n",
              " 'was afnan bad week had .',\n",
              " 'was i vulnerable feel .',\n",
              " 'you my friend be after yes no ?',\n",
              " 'was i french letter write .',\n",
              " 'truthful boy same answer reply with after not .',\n",
              " 'he you look now .',\n",
              " 'was we just talk .',\n",
              " 'was you canadian .',\n",
              " 'was i karachi stay had .',\n",
              " 'it seem she you hate .',\n",
              " 'was musayyab hospital die .',\n",
              " 'was nabi trap .',\n",
              " 'jalaal my car use let not .',\n",
              " 'i think your theory incorrect .',\n",
              " 'was jalaal fatima other splashed .',\n",
              " 'was i young innocent .',\n",
              " 'was they their separate call off .',\n",
              " 'me here stop let .',\n",
              " 'was they some coins put not .',\n",
              " 'mahi very funny .',\n",
              " 'was i queasy bit feel .',\n",
              " 'was i know you wait not .',\n",
              " 'mudassir fear eyes .',\n",
              " 'there very little was time was time was time was time was time was time was time',\n",
              " 'was i great vacation had .',\n",
              " 'i not .',\n",
              " 'was they it again do .',\n",
              " 'you it see full yes no ?',\n",
              " 'he river go to full after now not .',\n",
              " 'he approve after not .',\n",
              " 'was it terrorism .',\n",
              " 'i it doubt begin now .',\n",
              " 'you me excuse full after .',\n",
              " 'ishtiyaq help but look not .',\n",
              " 'was i myself a new camera buy .',\n",
              " 'i see after if abrar here .',\n",
              " 'i stay after .',\n",
              " 'was we school french study .',\n",
              " 'was he his house fence build .',\n",
              " 'shahid strange kid .',\n",
              " 'numan writer .',\n",
              " 'inam rain or rain or rain or rain or rain or rain or rain or rain or',\n",
              " 'i someone see now .',\n",
              " 'was i very nervous .',\n",
              " 'i ok be .',\n",
              " 'was numan windows roll down .',\n",
              " 'was aafaq afia talk let not .']"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "932B1kqmYaFk"
      },
      "source": [
        "groundt=groundt[:93]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1gRIs_yvLMF",
        "outputId": "7557d5f3-44ed-4ef8-8181-1cb41c459466"
      },
      "source": [
        "len(groundt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "93"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cekb4Xt2ELr",
        "outputId": "132e75df-20f7-475f-aaad-bc60a7921034"
      },
      "source": [
        "x[1].split()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['was', 'we', 'our', 'neighbors', 'see', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPDHdkO1rF6B",
        "outputId": "75a9c1c2-c57d-49b4-d2cb-1a7f1d88d6d1"
      },
      "source": [
        "g1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9285714285714286, 0.9285714285714286]"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEqtVHa1rNeM",
        "outputId": "fa9aab6a-d816-419f-cdce-97761a681515"
      },
      "source": [
        "g2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.09636241116594318, 0.9636241116594315]"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOYI-OYBrQZQ",
        "outputId": "3cc26056-01b1-47d5-fb7e-bd6152e1acec"
      },
      "source": [
        "g3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07192820457722461, 0.9780129266060039]"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0BeqgfQrR3c",
        "outputId": "76ff65af-a29f-4619-f51b-9b62db497532"
      },
      "source": [
        "g4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04007543120290852, 0.981643576691373]"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkOuNzc5g3ns"
      },
      "source": [
        "gram1=np.sum(g1[:65])/65\n",
        "gram2=np.sum(g2[:65])/65\n",
        "gram3=np.sum(g3[:65])/65\n",
        "gram4=np.sum(g4[:65])/65\n",
        "\n",
        "print(f'1-gram: {gram1} 2-gram: {gram2} 3-gram: {gram3} 4-gram: {gram4}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B0Z0tLGg3q7"
      },
      "source": [
        "plt.bar(x =['1-gram','2-gram','3-gram','4-gram'], height =[gram1,gram2,gram3,gram4] )\n",
        "plt.title(\"Average BLEU Score\")\n",
        "plt.ylim((0,1))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2v4ZC6d0g3uK",
        "outputId": "c329f5e9-49f7-40eb-cc96-bd17fae14783"
      },
      "source": [
        "!pip install jiwer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jiwer\n",
            "  Downloading jiwer-2.2.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from jiwer) (1.19.5)\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▌                         | 10 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 30 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 40 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 50 kB 3.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein->jiwer) (57.4.0)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149863 sha256=19fdb8a72a87b83d62af7b688d77c60243ff56b706dcad9049e73263cc2f9139\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein, jiwer\n",
            "Successfully installed jiwer-2.2.0 python-Levenshtein-0.12.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R550MJVGrczw",
        "outputId": "739cc0a1-47c7-42f5-b409-e1231dada239"
      },
      "source": [
        "len(groundt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBLucnCbroYu"
      },
      "source": [
        "groundt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fvfq2yGPg3wq",
        "outputId": "f15e7cac-1c2f-41e9-87e1-400218f9be51"
      },
      "source": [
        "from jiwer import wer\n",
        "e=0\n",
        "for i in range(len(groundt)):\n",
        "  e+=wer(groundt[i],x[i])\n",
        "\n",
        "print(f'WER: {e/100}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER: 0.2212896825396825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfwJLEe6w3C4",
        "outputId": "fcf33981-e8c4-4f94-b4de-33b65399a027"
      },
      "source": [
        "e/93"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9518731865506055"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqJV33s5hDWA",
        "outputId": "14f70cc9-2c3f-4bab-f2f0-3712d374bf26"
      },
      "source": [
        "!pip install pyter3\n",
        "import pyter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyter3 in /usr/local/lib/python3.7/dist-packages (0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qg6WBf55sD1u",
        "outputId": "348e996a-b36e-4658-8d5c-97991cc1aeb2"
      },
      "source": [
        "print(pyter.ter(groundt[92].split(),result[92].split()[:-1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aLIjSCQhDYz"
      },
      "source": [
        "tererror=0\n",
        "l=0\n",
        "for i in range(len(groundt)):\n",
        "  # tererror=pyter.ter(groundt[i].split(),result[i].split())\n",
        "  tererror+=pyter.ter(groundt[i].split(),x[i].split())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNZKO6aAtjiG",
        "outputId": "bde68b8d-8cf1-4ea5-c41f-5ca6d1fce814"
      },
      "source": [
        "len(tererror)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "93"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4DTM1OthDcS",
        "outputId": "e20d8c43-7edb-4019-df99-9a18866f0afb"
      },
      "source": [
        "tererror/100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1496442577030812"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugUBvXaAg3zp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNHFurzzSMv0"
      },
      "source": [
        "f= open('/content/predict.txt','r+')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSgHHqsbWAQf"
      },
      "source": [
        "file3 = open(\"/content/predict2.txt\",\"w\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOyYzVf4SMzJ",
        "outputId": "ae324b0f-a265-4b34-e6c7-696fa2a7e80a"
      },
      "source": [
        "prprocess=list()\n",
        "for i in f:\n",
        "  print(i[:-7])\n",
        "  file3.writelines(i[:-7]+'\\n')\n",
        "file3.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "she his room go yes no ? \n",
            "was mahi dua close friends . \n",
            "was he many dangers absorb . \n",
            "azan uninsure . \n",
            "the dog milkman bark at now after not . \n",
            "was my grandfather house house house house house house house house house house house house house \n",
            "i know not i know not i know not i know not i know not i\n",
            "was her mother him advise not . \n",
            "they robbers abdul qadir jilani the soil the soil the soil the soil the soil the\n",
            "was he happy . \n",
            "was she beautiful hat show . \n",
            "i zabhi rid get now . \n",
            "was khayam them closely look . \n",
            "i come now . \n",
            "was you go . \n",
            "was i help . \n",
            "i several moheem moheem moheem moheem moheem moheem moheem moheem moheem moheem moheem moheem moheem moheem m\n",
            "i her sister a much like . \n",
            "was i it notice . \n",
            "i you know after . \n",
            "was i lot learn hope now . \n",
            "was nazeer gazala do see . \n",
            "i think fahad cooperative be not . \n",
            "was i pakistan work use . \n",
            "was i play want . \n",
            "was izatullah later short time leave . \n",
            "i now know . \n",
            "i them see . \n",
            "i my room clean full now not yes no ? \n",
            "arif room clean yes no ? \n",
            "you able come be after yes no ? \n",
            "was pigeons grass sit on full . \n",
            "i sameer questions ask . \n",
            "was i it wrong . \n",
            "was manan our house come want . \n",
            "irfan ul haq curious . \n",
            "was arif optimistic not . \n",
            "was adeel crack hear adeel crack hear adeel crack hear adeel crack hear adeel crack hear \n",
            "was sajid alert . \n",
            "was she her left burned . \n",
            "was i home stay . \n",
            "was i this place use . \n",
            "was i even there not . \n",
            "was manan drown . \n",
            "was i high school go . \n",
            "was ajab interest not . \n",
            "was i my suitcase carry get . \n",
            "was i hear najeeb get najeeb get najeeb get najeeb get najeeb get najeeb get najee\n",
            "she her mother help full now yes no ? \n",
            "was shamas phone handed . \n",
            "was she my aid come . \n",
            "i my life like . \n",
            "i aslam here tonight be expect . \n",
            "i my reasons have . \n",
            "was arman his day us tell . \n",
            "was hassan stalls go to full now not . \n",
            "i you contradict now not . \n",
            "gardener turban wear full after not . \n",
            "was jan his teacher call . \n",
            "was you book like yes no ? \n",
            "i really you me call . \n",
            "he it prove . \n",
            "musawir prospector . \n",
            "tulat think was para always think was para always think was para always think was para a\n",
            "it drink down . \n",
            "was i women like . \n",
            "asma out go not yes no ? \n",
            "was aslam altogether altogether altogether altogether altogether altogether altogether altogether altogether altogether altogether altogether altogether altogether altog\n",
            "was sharjeel me sick . \n",
            "was i note write . \n",
            "we library speak full after now not . \n",
            "i your shirt dry after . \n",
            "i know not when was aman die . \n",
            "you me remember after . \n",
            "was they desert pass through full . \n",
            "it very dangerous . \n",
            "just it stop . \n",
            "i stairs go down now . \n",
            "was bears cold water sit in full now . \n",
            "i you it do let not . \n",
            "azaan art love . \n",
            "was we anyone tell not . \n",
            "was arif there again want . \n",
            "i terrible mistake make full . \n",
            "she live there anymore not . \n",
            "was ameer unfriendly be use . \n",
            "buzdar famous artist . \n",
            "you my keys get full . \n",
            "was i today work go not . \n",
            "was i wrong approach choose . \n",
            "little grains of sand the land make full not . \n",
            "i usually outside eat . \n",
            "was safeer it do . \n",
            "i it here like not . \n",
            "i it touch yes no ? \n",
            "was they old woman run towards not yes no ? \n",
            "shahzad often late stay out . \n",
            "was he unconcerned . \n",
            "i know it tough be after . \n",
            "was i just confuse . \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8T7FBGSSM24",
        "outputId": "400dc288-4ad5-40b3-b8d2-b59062b0e7ea"
      },
      "source": [
        "prprocess"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['she his room go yes no ? ',\n",
              " 'was mahi dua close friends . ',\n",
              " 'was he many dangers absorb . ',\n",
              " 'azan uninsure . ',\n",
              " 'the dog milkman bark at now after not . ',\n",
              " 'was my grandfather house house house house house house house house house house house house house ',\n",
              " 'i know not i know not i know not i know not i know not i',\n",
              " 'was her mother him advise not . ',\n",
              " 'they robbers abdul qadir jilani the soil the soil the soil the soil the soil the',\n",
              " 'was he happy . ',\n",
              " 'was she beautiful hat show . ',\n",
              " 'i zabhi rid get now . ',\n",
              " 'was khayam them closely look . ',\n",
              " 'i come now . ',\n",
              " 'was you go . ',\n",
              " 'was i help . ',\n",
              " 'i several moheem moheem moheem moheem moheem moheem moheem moheem moheem moheem moheem moheem moheem moheem m',\n",
              " 'i her sister a much like . ',\n",
              " 'was i it notice . ',\n",
              " 'i you know after . ',\n",
              " 'was i lot learn hope now . ',\n",
              " 'was nazeer gazala do see . ',\n",
              " 'i think fahad cooperative be not . ',\n",
              " 'was i pakistan work use . ',\n",
              " 'was i play want . ',\n",
              " 'was izatullah later short time leave . ',\n",
              " 'i now know . ',\n",
              " 'i them see . ',\n",
              " 'i my room clean full now not yes no ? ',\n",
              " 'arif room clean yes no ? ',\n",
              " 'you able come be after yes no ? ',\n",
              " 'was pigeons grass sit on full . ',\n",
              " 'i sameer questions ask . ',\n",
              " 'was i it wrong . ',\n",
              " 'was manan our house come want . ',\n",
              " 'irfan ul haq curious . ',\n",
              " 'was arif optimistic not . ',\n",
              " 'was adeel crack hear adeel crack hear adeel crack hear adeel crack hear adeel crack hear ',\n",
              " 'was sajid alert . ',\n",
              " 'was she her left burned . ',\n",
              " 'was i home stay . ',\n",
              " 'was i this place use . ',\n",
              " 'was i even there not . ',\n",
              " 'was manan drown . ',\n",
              " 'was i high school go . ',\n",
              " 'was ajab interest not . ',\n",
              " 'was i my suitcase carry get . ',\n",
              " 'was i hear najeeb get najeeb get najeeb get najeeb get najeeb get najeeb get najee',\n",
              " 'she her mother help full now yes no ? ',\n",
              " 'was shamas phone handed . ',\n",
              " 'was she my aid come . ',\n",
              " 'i my life like . ',\n",
              " 'i aslam here tonight be expect . ',\n",
              " 'i my reasons have . ',\n",
              " 'was arman his day us tell . ',\n",
              " 'was hassan stalls go to full now not . ',\n",
              " 'i you contradict now not . ',\n",
              " 'gardener turban wear full after not . ',\n",
              " 'was jan his teacher call . ',\n",
              " 'was you book like yes no ? ',\n",
              " 'i really you me call . ',\n",
              " 'he it prove . ',\n",
              " 'musawir prospector . ',\n",
              " 'tulat think was para always think was para always think was para always think was para a',\n",
              " 'it drink down . ',\n",
              " 'was i women like . ',\n",
              " 'asma out go not yes no ? ',\n",
              " 'was aslam altogether altogether altogether altogether altogether altogether altogether altogether altogether altogether altogether altogether altogether altogether altog',\n",
              " 'was sharjeel me sick . ',\n",
              " 'was i note write . ',\n",
              " 'we library speak full after now not . ',\n",
              " 'i your shirt dry after . ',\n",
              " 'i know not when was aman die . ',\n",
              " 'you me remember after . ',\n",
              " 'was they desert pass through full . ',\n",
              " 'it very dangerous . ',\n",
              " 'just it stop . ',\n",
              " 'i stairs go down now . ',\n",
              " 'was bears cold water sit in full now . ',\n",
              " 'i you it do let not . ',\n",
              " 'azaan art love . ',\n",
              " 'was we anyone tell not . ',\n",
              " 'was arif there again want . ',\n",
              " 'i terrible mistake make full . ',\n",
              " 'she live there anymore not . ',\n",
              " 'was ameer unfriendly be use . ',\n",
              " 'buzdar famous artist . ',\n",
              " 'you my keys get full . ',\n",
              " 'was i today work go not . ',\n",
              " 'was i wrong approach choose . ',\n",
              " 'little grains of sand the land make full not . ',\n",
              " 'i usually outside eat . ',\n",
              " 'was safeer it do . ',\n",
              " 'i it here like not . ',\n",
              " 'i it touch yes no ? ',\n",
              " 'was they old woman run towards not yes no ? ',\n",
              " 'shahzad often late stay out . ',\n",
              " 'was he unconcerned . ',\n",
              " 'i know it tough be after . ',\n",
              " 'was i just confuse . ']"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NflVVAduSM61"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNYPDYL4SM_x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GaEXMvBSNDf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_-t9xxISNF-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1awncyySNIp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37-I3BV1gygP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}